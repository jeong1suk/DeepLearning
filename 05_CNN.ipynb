{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "mount_file_id": "14StOvgkkQ7lS2898BBG3p_OENnBUY-iP",
      "authorship_tag": "ABX9TyNTXiY8AeqKXRkNHFpMmdXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeong1suk/DeepLearning/blob/main/05_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fashion Mnist DNN Tutorial (CNN & Multi-layer Perceptron(MLP))"
      ],
      "metadata": {
        "id": "6b3QId7yQ4XX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 외부 파일 가져오기 & requirements 설치"
      ],
      "metadata": {
        "id": "ScPQP96dQfLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "JGGL2hW5Q2Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_project_root = '/content/drive/MyDrive/#fastcampus'\n",
        "sys.path.append(drive_project_root)"
      ],
      "metadata": {
        "id": "T1TRHr4-Pztc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""
      ],
      "metadata": {
        "id": "2-ld-X6cRF_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_optimizer"
      ],
      "metadata": {
        "id": "7LoGjmamLcjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "wK1vQ-CmLr7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf"
      ],
      "metadata": {
        "id": "hl2lMdciRaY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from omegaconf import OmegaConf\n",
        "from omegaconf import DictConfig\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch_optimizer import RAdam\n",
        "from torch_optimizer import AdamP\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import wandb"
      ],
      "metadata": {
        "id": "5l177iqcRhPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data_utils import dataset_split"
      ],
      "metadata": {
        "id": "Pt1kKVw7YSU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = os.path.join(os.getcwd(), 'data')\n",
        "# '/content' 경로에 'data'라고하는 폴더를 추가해서 데이터를 저장.\n",
        "\n",
        "# 전처리 부분 (preprocessing) & 데이터셋 정의\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5]), # mean, std\n",
        "    ]\n",
        "\n",
        ")\n",
        "fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)"
      ],
      "metadata": {
        "id": "vciDPxFUVBAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist_dataset[0][1]"
      ],
      "metadata": {
        "id": "RHdhJ6-8VHgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "dset = random_split(\n",
        "    fashion_mnist_dataset,\n",
        "    [int(len(fashion_mnist_dataset)*0.7), len(fashion_mnist_dataset)-int(len(fashion_mnist_dataset)*0.7)]\n",
        ")\n",
        "# 이 코드로 해도 되지만, 랜덤성이 있기 때문에 util함수를 만들어서 split을 해준다.\n",
        "'''"
      ],
      "metadata": {
        "id": "XT5U4PssW6Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGtQDx-XXVfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader를 정의"
      ],
      "metadata": {
        "id": "zLi3eYZPaFMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = dataset_split(fashion_mnist_dataset, split=[0.9, 0.1])\n",
        "print(datasets)\n",
        "\n",
        "train_dataset = datasets[\"train\"]\n",
        "val_dataset = datasets[\"val\"]\n",
        "\n",
        "train_batch_size = 100 # 한번에 얼마나 업데이트를 할 것 인지\n",
        "val_batch_size = 100\n",
        "#DataLoader = batch 단위로 묶는 것\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=1\n",
        ")\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=1\n",
        ")"
      ],
      "metadata": {
        "id": "nkvDHDHpZH4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample_batch in train_dataloader:\n",
        "    print(sample_batch)\n",
        "    print(sample_batch[0].shape, sample_batch[1].shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "lCVai6jRZXzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 (Multi-layer Perceptron) (MLP) 정의\n"
      ],
      "metadata": {
        "id": "8kyCOTJEaZRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 MLPWithDropout 정의"
      ],
      "metadata": {
        "id": "k9ymLAumglUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(in_dim, h1_dim)\n",
        "        self.linear2 = nn.Linear(h1_dim, h2_dim)\n",
        "        self.linear3 = nn.Linear(h2_dim, out_dim)\n",
        "        self.relu = F.relu\n",
        "        pass\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = torch.flatten(input, start_dim=1)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        out = self.linear3(x)\n",
        "        # out = F.softmax(out)\n",
        "        return out\n",
        "\n",
        "class MLPWithDropout(MLP):\n",
        "    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n",
        "        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = torch.flatten(input, start_dim=1)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.dropout2(x)\n",
        "        out = self.linear3(x)\n",
        "        # out = F.softmax(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "3MEBhxFqaMrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN 모델 정의"
      ],
      "metadata": {
        "id": "G0WYdYsgQUo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_cnn_cfg_dict = {\n",
        "    \"layer_1\": {\n",
        "        \"conv2d_in_channels\": 1,\n",
        "        \"conv2d_out_channels\": 32,\n",
        "        \"conv2d_kernel_size\": 3,\n",
        "        \"conv2d_padding\": 1,\n",
        "        \"maxpool2d_kernel_size\": 2,\n",
        "        \"maxpool2d_stride\": 2,\n",
        "    },\n",
        "    \"layer_2\": {\n",
        "        \"conv2d_in_channels\": 32,\n",
        "        \"conv2d_out_channels\": 64,\n",
        "        \"conv2d_kernel_size\": 3,\n",
        "        \"conv2d_padding\": 0,\n",
        "        \"maxpool2d_kernel_size\": 2,\n",
        "        \"maxpool2d_stride\": 1,\n",
        "    },\n",
        "    \"fc_1\": {\n",
        "        \"in_features\": 7744, # 값 보고 수정하기.\n",
        "        \"out_features\": 512,\n",
        "    },\n",
        "    \"fc_2\": {\n",
        "        \"in_features\": 512,\n",
        "        \"out_features\": 128,\n",
        "    },\n",
        "    \"fc_3\": {\n",
        "        \"in_features\": 128,\n",
        "        \"out_features\": 10,\n",
        "    },\n",
        "    \"dropout_prob\": 0.25\n",
        "}\n",
        "_cnn_cfg = OmegaConf.create(_cnn_cfg_dict)\n",
        "# print(_cnn_cfg)\n",
        "print(OmegaConf.to_yaml(_cnn_cfg))\n",
        "# with open(\"cnn_test.yaml\", \"w\") as f:\n",
        "    # OmegaConf.save(_cnn_cfg, f)\n",
        "# print(_cnn_cfg.layer_1, _cnn_cfg[\"fc_1\"])\n",
        "# OmegaConf.load()\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, cfg: DictConfig = _cnn_cfg):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=cfg.layer_1.conv2d_in_channels,\n",
        "                out_channels=cfg.layer_1.conv2d_out_channels,\n",
        "                kernel_size=cfg.layer_1.conv2d_kernel_size,\n",
        "                padding=cfg.layer_1.conv2d_padding,\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=cfg.layer_1.conv2d_out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(\n",
        "                kernel_size=cfg.layer_1.maxpool2d_kernel_size,\n",
        "                stride=cfg.layer_1.maxpool2d_stride\n",
        "            )\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=cfg.layer_2.conv2d_in_channels,\n",
        "                out_channels=cfg.layer_2.conv2d_out_channels,\n",
        "                kernel_size=cfg.layer_2.conv2d_kernel_size,\n",
        "                padding=cfg.layer_2.conv2d_padding,\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=cfg.layer_2.conv2d_out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(\n",
        "                kernel_size=cfg.layer_2.maxpool2d_kernel_size,\n",
        "                stride=cfg.layer_2.maxpool2d_stride\n",
        "            )\n",
        "        )\n",
        "        self.fc1 = nn.Linear(\n",
        "            in_features=cfg.fc_1.in_features,\n",
        "            out_features=cfg.fc_1.out_features,\n",
        "        )\n",
        "        self.fc2 = nn.Linear(\n",
        "            in_features=cfg.fc_2.in_features,\n",
        "            out_features=cfg.fc_2.out_features,\n",
        "        )\n",
        "        self.fc3 = nn.Linear(\n",
        "            in_features=cfg.fc_3.in_features,\n",
        "            out_features=cfg.fc_3.out_features,\n",
        "        )\n",
        "        self.dropout = nn.Dropout2d(cfg.dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1) # flatten\n",
        "        out = self.fc1(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "CNN()"
      ],
      "metadata": {
        "id": "iI0euGR6QWlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "6H_eVTZHY2gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Warmup Scheduler\n",
        "class WarmupLR(optim.lr_scheduler.LambdaLR):\n",
        "    def __init__(\n",
        "            self, optimizer: optim.Optimizer,\n",
        "            warmup_end_steps:int,\n",
        "            last_epoch: int = -1,\n",
        "        ):\n",
        "        def warmup_fn(step: int):\n",
        "            if step < warmup_end_steps:\n",
        "                return float(step) / float(max(warmup_end_steps, 1))\n",
        "            return 1.0\n",
        "\n",
        "        super().__init__(optimizer, warmup_fn, last_epoch)\n"
      ],
      "metadata": {
        "id": "wI3llt7qY4xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 선언 및 손실 함수, 최적화(Optimization) 정의, Tensorboard Logger 정의"
      ],
      "metadata": {
        "id": "x6Aw8IePb6Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu setup\n",
        "# gpu = None\n",
        "gpu = 0 # gpu 0번 쓰겠다.\n",
        "\n",
        "# define model.\n",
        "# model = MLP(28*28, 128, 64, 10)\n",
        "# model = MLPWithDropout(28*28, 128, 64, 10, dropout_prob=0.3)\n",
        "model = CNN(cfg=_cnn_cfg)\n",
        "if gpu is not None:\n",
        "    model.cuda(gpu)\n",
        "model_name = type(model).__name__\n",
        "print(model_name)\n",
        "\n",
        "# define loss\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# define optimizer\n",
        "lr = 1e-3\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "optimizer = RAdam(model.parameters(), lr=1e-3)\n",
        "# optimizer = AdamP(model.parameters(), lr=1e-3)\n",
        "optimizer_name = type(optimizer).__name__\n",
        "\n",
        "# define scheduler\n",
        "scheduler = None\n",
        "# scheduler = WarmupLR(optimizer, 1500)\n",
        "scheduler_name = type(scheduler).__name__ if scheduler is not None else \"no\"\n",
        "\n",
        "max_epoch = 50\n",
        "\n",
        "# define tensorboard logger\n",
        "# 여러개를 돌릴 거기 때문에 로그 디렉토리를 관리해줌.\n",
        "run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{model_name}-{optimizer_name}_optim_{lr}_lr_with_{scheduler_name}_scheduler\"\n",
        "run_dirname = \"dnn-tutorial-fashion-mnist-runs\"\n",
        "# log_dir = f\"runs/{run_name}\"\n",
        "log_dir = os.path.join(drive_project_root, \"runs\", run_dirname, run_dirname)\n",
        "writer = SummaryWriter(log_dir=log_dir)\n",
        "log_interval = 100\n",
        "\n",
        "# define wandb\n",
        "project_name = \"fashion_mnist_tutorials\"\n",
        "run_tags = [project_name]\n",
        "wandb.init(\n",
        "    project=project_name,\n",
        "    name=run_name,\n",
        "    tags=run_tags,\n",
        "    config={\"lr\":lr, \"model_name\":model_name, \"optimizer_name\": optimizer_name, \"scheduler_name\":scheduler_name},\n",
        "    reinit=True,\n",
        ")\n",
        "wandb.watch(model)\n",
        "\n",
        "# set save model path\n",
        "log_model_path = os.path.join(log_dir, \"models\")\n",
        "os.makedirs(log_model_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "atG62Dfmb5m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케쥴링을 보기 위한 코드\n",
        "# for i in range(100):\n",
        "#     print(\"step\", i)\n",
        "#     optimizer.step()\n",
        "#     scheduler.step()\n",
        "#     print(scheduler.get_last_lr())"
      ],
      "metadata": {
        "id": "BRqPzBS1aHNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early Stopping callback Object Class 정의"
      ],
      "metadata": {
        "id": "6qIOcP5VgaMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With some modifications, source is from https://github.com/Bjarten/early-stopping-pytorch\n",
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Early stops the training if validation loss doesn't improve after a given patience.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path=\"checkpoint.ckpt\", trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                Defalut: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                Defalut: False\n",
        "            delta (float):  Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                Defalut: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                Defalut: 'checkpoint.ckpt'\n",
        "            trace_func (function): trace print function.\n",
        "                Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "\n",
        "        filename = self.path.split('/')[-1]\n",
        "        save_dir = os.path.dirname(self.path)\n",
        "        torch.save(model, os.path.join(save_dir, f\"val_loss-{val_loss}-{filename}\"))\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "f8t8EK6ygeG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-tutorial-fashion-mnist-runs/\n",
        "\n",
        "# define EarlyStopping.\n",
        "early_stopper = EarlyStopping(\n",
        "    patience=3, verbose=True, path=os.path.join(log_model_path, \"model.ckpt\")\n",
        ")\n",
        "\n",
        "# do train with validation\n",
        "train_step = 0\n",
        "for epoch in range(1, max_epoch+1):\n",
        "    # valid step\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        model.eval()\n",
        "\n",
        "        for val_batch_idx, (val_images, val_labels) in enumerate(\n",
        "            tqdm(val_dataloader, position=0, leave=True, desc=\"validation\")\n",
        "        ):\n",
        "            if gpu is not None:\n",
        "                val_images = val_images.cuda(gpu)\n",
        "                val_labels = val_labels.cuda(gpu)\n",
        "                # print(\"ㅗㄷㅁㄱ\", gpu)\n",
        "            # Forward\n",
        "            val_outputs = model(val_images)\n",
        "            _, val_preds = torch.max(val_outputs, 1)\n",
        "\n",
        "            # loss & acc\n",
        "            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0]\n",
        "            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n",
        "\n",
        "    # valid step logging\n",
        "    val_epoch_loss = val_loss / len(val_dataloader)\n",
        "    val_epoch_acc = val_corrects / len(val_dataloader)\n",
        "\n",
        "    print(\n",
        "        f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n",
        "    )\n",
        "\n",
        "    #tensorboard log\n",
        "    writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n",
        "    writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n",
        "    writer.add_images(\"Images/val\", val_images, train_step)\n",
        "\n",
        "    # wandb log\n",
        "    wandb.log({\n",
        "        \"Loss/val\": val_epoch_loss,\n",
        "        \"Acc/val\": val_epoch_acc,\n",
        "        \"Images/val\": wandb.Image(val_images),\n",
        "        \"Outputs/val\": wandb.Histogram(val_outputs.detach().cpu().numpy()),\n",
        "        \"Preds/val\": wandb.Histogram(val_preds.detach().cpu().numpy()),\n",
        "        \"Labels/val\": wandb.Histogram(val_labels.data.detach().cpu().numpy()),\n",
        "    }, step=train_step)\n",
        "\n",
        "    # check model early stopping point & save model if model reached the best performance.\n",
        "    early_stopper(val_epoch_loss, model)\n",
        "    if early_stopper.early_stop:\n",
        "        break\n",
        "\n",
        "    #train step\n",
        "    current_loss = 0\n",
        "    current_corrects = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(\n",
        "        tqdm(train_dataloader, position=0, leave=True, desc=\"training\")\n",
        "    ):\n",
        "\n",
        "        if gpu is not None:\n",
        "            images = images.cuda(gpu)\n",
        "            labels = labels.cuda(gpu)\n",
        "\n",
        "        current_loss = 0.0\n",
        "        current_corrects = 0\n",
        "\n",
        "        # Forward\n",
        "        # get predictions\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # get loss (Loss 계산)\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        # Optimizer 초기화 (zero화)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform Opimization\n",
        "        optimizer.step()\n",
        "\n",
        "        # Perform LR Scheduler work\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        current_loss += loss.item()\n",
        "        current_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        if train_step % log_interval == 0:\n",
        "            train_loss = current_loss / log_interval\n",
        "            train_acc = current_corrects / log_interval\n",
        "\n",
        "            print(\n",
        "                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\"\n",
        "            )\n",
        "            if scheduler is None:\n",
        "                cur_lr = optimizer.param_groups[0][\"lr\"]\n",
        "            else:\n",
        "                cur_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "            # tensorboard log\n",
        "            writer.add_scalar(\"Loss/train\", train_loss, train_step)\n",
        "            writer.add_scalar(\"Acc/train\", train_acc, train_step)\n",
        "            writer.add_images(\"Images/train\", images, train_step)\n",
        "            writer.add_scalar(\"Learning Rate\", cur_lr, train_step) # 스케쥴러를 설정하면 lr이 바뀌기 때문에 logging\n",
        "            writer.add_graph(model, images)\n",
        "\n",
        "            # wandb log\n",
        "            wandb.log({\n",
        "                \"Loss/train\": train_loss,\n",
        "                \"Acc/train\": train_acc,\n",
        "                \"Images/train\": wandb.Image(images),\n",
        "                \"Outputs/train\": wandb.Histogram(outputs.detach().cpu().numpy()),\n",
        "                \"Preds/train\": wandb.Histogram(preds.detach().cpu().numpy()),\n",
        "                \"Labels/train\": wandb.Histogram(labels.data.detach().cpu().numpy()),\n",
        "                \"Learning Rate\": cur_lr,\n",
        "            }, step=train_step)\n",
        "\n",
        "            current_loss = 0\n",
        "            current_corrects = 0\n",
        "\n",
        "        train_step += 1"
      ],
      "metadata": {
        "id": "2Xhn8DfrcXcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "# torch.save(model, os.path.join(log_model_path, \"model.ckpt\"))"
      ],
      "metadata": {
        "id": "2UHjgl8ycu_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_model_path"
      ],
      "metadata": {
        "id": "2-ukuMl-lzZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load models\n",
        "# loaded_model = torch.load(os.path.join(log_model_path, \"model.ckpt\"))\n",
        "# loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.003235985990613699-model.ckpt\"))\n",
        "loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.0023227857891470194-model.ckpt\"))\n",
        "loaded_model.eval()\n",
        "loaded_model.cpu()\n",
        "print(loaded_model)"
      ],
      "metadata": {
        "id": "_qY4vIQzkuw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x, axis=0):\n",
        "    \"numpy softmax\"\n",
        "    max = np.max(x, axis=axis, keepdims=True)\n",
        "    e_x = np.exp(x - max)\n",
        "    sum = np.sum(e_x, axis=axis, keepdims=True)\n",
        "    f_x = e_x / sum\n",
        "    return f_x"
      ],
      "metadata": {
        "id": "uq1RFFbUk31O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch_size = 100\n",
        "test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n",
        "\n",
        "test_labels_list = []\n",
        "test_preds_list = []\n",
        "test_outputs_list = []\n",
        "for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n",
        "    # forward\n",
        "    test_outputs = loaded_model(test_images)\n",
        "    _, test_preds = torch.max(test_outputs, 1)\n",
        "\n",
        "    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n",
        "    test_outputs_list.extend(final_outs)\n",
        "    test_preds_list.extend(test_preds.detach().numpy())\n",
        "    test_labels_list.extend(test_labels.detach().numpy())\n",
        "\n",
        "\n",
        "test_preds_list = np.array(test_preds_list)\n",
        "test_labels_list = np.array(test_labels_list)\n",
        "\n",
        "print(f\"\\nacc: {np.mean(test_preds_list == test_labels_list)*100}%\")"
      ],
      "metadata": {
        "id": "-aRu2mQGlSAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC Curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "threshold = {}\n",
        "n_class = 10\n",
        "\n",
        "for i in range(n_class):\n",
        "    fpr[i], tpr[i], threshold[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n",
        "\n",
        "# plot\n",
        "for i in range(n_class):\n",
        "    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n",
        "plt.title(\"Multi-class ROC Curve\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n",
        "\n",
        "print(\"auc_score: \", roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"))"
      ],
      "metadata": {
        "id": "Yu1mrObSmRGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJWx8QOHnHxY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
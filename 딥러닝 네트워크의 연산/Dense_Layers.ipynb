{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPRdLgEJ/Po+KyG/J5+zN7/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeong1suk/DeepLearning/blob/math/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EC%9D%98%20%EC%97%B0%EC%82%B0/Dense_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2-1: Dense Layers"
      ],
      "metadata": {
        "id": "6nxy3M5bcK_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code.2-1-1: Shapes of Dense Layers"
      ],
      "metadata": {
        "id": "cxNgzX2HcNdC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2kwJCnncH5T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.math import exp\n",
        "from tensorflow.linalg import matmul\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N, n_feature = 1, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "n_neuron = 3\n",
        "dense = Dense(units=n_neuron, activation=\"sigmoid\")\n",
        "Y = dense(X)\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "print(\"==== Input/Weight/Bias ====\")\n",
        "print(\"X: \", X.shape)\n",
        "print(\"W: \", W.shape)\n",
        "print(\"B: \", B.shape)\n",
        "print(\"Y: \", Y.shape)\n",
        "\n",
        "print(W)"
      ],
      "metadata": {
        "id": "NdXZNZ9GcVEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N, n_feature = 8, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "n_neuron = 3\n",
        "dense = Dense(units=n_neuron, activation=\"sigmoid\")\n",
        "Y = dense(X)\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "print(\"==== Input/Weight/Bias ====\")\n",
        "print(\"X: \", X.shape)\n",
        "print(\"W: \", W.shape)\n",
        "print(\"B: \", B.shape)\n",
        "print(\"Y: \", Y.shape)"
      ],
      "metadata": {
        "id": "orglFzYmdCXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N, n_feature = 4, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "n_neuron = 3\n",
        "dense = Dense(units=n_neuron, activation=\"sigmoid\")\n",
        "Y_tf = dense(X)\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "print(\"Y(Tensorflow): \\n\", Y_tf.numpy())\n",
        "\n",
        "# calculate with matrix multiplication\n",
        "Z = matmul(X, W) + B\n",
        "Y_man_matmul = 1 / (1 + exp(-Z))\n",
        "print(\"Y(with matrix multiplication): \\n\", Y_man_matmul)\n",
        "\n",
        "# calculate with dot product\n",
        "Y_man_vec = np.zeros(shape=(N, n_neuron))\n",
        "\n",
        "for x_idx in range(N):\n",
        "    x = X[x_idx]\n",
        "\n",
        "    for nu_idx in range(n_neuron):\n",
        "        w, b = W[:, nu_idx], B[nu_idx]\n",
        "\n",
        "        z = tf.reduce_sum(x * w) + b\n",
        "        a = 1 / (1 + np.exp(-z))\n",
        "        Y_man_vec[x_idx, nu_idx] = a\n",
        "\n",
        "print(\"Y(with dot product): \\n\", Y_man_vec)"
      ],
      "metadata": {
        "id": "lSHNutEqdM2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2-2: Cascaded Dense Layers"
      ],
      "metadata": {
        "id": "ja2Mq4TY6zWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code.2-2-1: Shapes of Cascaded Dense Layers"
      ],
      "metadata": {
        "id": "SCHam7PT62YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 4, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "n_neurons = [3, 5]\n",
        "dense1 = Dense(units=n_neurons[0], activation='sigmoid')\n",
        "dense2 = Dense(units=n_neurons[1], activation='sigmoid')\n",
        "\n",
        "# forward propagation\n",
        "A1 = dense1(X)\n",
        "Y = dense2(A1)\n",
        "\n",
        "# get weight/bias\n",
        "W1, B1 = dense1.get_weights()\n",
        "W2, B2 = dense2.get_weights()\n",
        "\n",
        "print(\"X: {}\\n\".format(X.shape))\n",
        "\n",
        "print(\"W1: \", W1.shape)\n",
        "print(\"B1: \", B1.shape)\n",
        "print(\"A1: {}\\n\".format(A1.shape))\n",
        "\n",
        "print(\"W2: \", W2.shape)\n",
        "print(\"B2: \", B2.shape)\n",
        "print(\"Y: {}\\n\".format(Y.shape))"
      ],
      "metadata": {
        "id": "sGQ7h_Bvdqkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code.2-2-2: Dense Layers with Python List"
      ],
      "metadata": {
        "id": "GBYQVume7-Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 4, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "n_neurons = [10, 20, 30, 40, 50, 60 ,70 ,80, 90, 100]\n",
        "\n",
        "dense_layers = list()\n",
        "for n_neuron in n_neurons:\n",
        "    dense = Dense(units=n_neuron, activation='relu')\n",
        "    dense_layers.append(dense)\n",
        "\n",
        "print(\"Input: \", X.shape)\n",
        "for dense_idx, dense in enumerate(dense_layers):\n",
        "    X = dense(X)\n",
        "    print(\"After dense layer \", dense_idx+1)\n",
        "    print(X.shape, '\\n')\n"
      ],
      "metadata": {
        "id": "xFylxMMY7YZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code.2-2-3: Output Calculations"
      ],
      "metadata": {
        "id": "JXZJ4kZz9KAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.math import exp\n",
        "from tensorflow.linalg import matmul\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 4, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "X_cp = tf.identity(X)\n",
        "\n",
        "n_neurons = [3, 4, 5]\n",
        "\n",
        "dense_layers = list()\n",
        "for n_neuron in n_neurons:\n",
        "    dense = Dense(units=n_neuron, activation='sigmoid')\n",
        "    dense_layers.append(dense)\n",
        "\n",
        "# forward propagation(Tensorflow)\n",
        "W, B = list(), list()\n",
        "for dense_idx, dense in enumerate(dense_layers):\n",
        "    X = dense(X)\n",
        "    w, b = dense.get_weights()\n",
        "\n",
        "    W.append(w)\n",
        "    B.append(b)\n",
        "\n",
        "print(\"Y(Tensorflow): \\n\", X.numpy())\n",
        "\n",
        "# forward propagation(Manual)\n",
        "for layer_idx in range(len(n_neurons)):\n",
        "    w, b = W[layer_idx], B[layer_idx]\n",
        "\n",
        "    X_cp = matmul(X_cp, w) + b\n",
        "    X_cp = 1 / (1 + exp(-X_cp))\n",
        "\n",
        "print(\"Y(Manual): \\n\", X_cp.numpy())"
      ],
      "metadata": {
        "id": "XU5HA3P-8UX6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}